{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CSV file and TSV file\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "H9L0gEZLCjt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the csv file\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "-pmda-m3CtEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-0dK49dCfAp"
      },
      "outputs": [],
      "source": [
        "# parameter sep\n",
        "df = df.read_csv(\"data.csv\", sep = ',')   # however its by default for csv file\n",
        "\n",
        "# to read the tsv file set sep = /t\n",
        "\n",
        "df = df.read_csv(\"data.tsv\", sep = '/t')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name parameter --> if  a dataset doesn't have a header then pass the array of header/column names inside a name parameter "
      ],
      "metadata": {
        "id": "WslIRnGMDPNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.read_csv(\"data.csv\", name = ['S.No','Name', 'enroll','result'])\n"
      ],
      "metadata": {
        "id": "xK11ihwjDe0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Index_col"
      ],
      "metadata": {
        "id": "P85vBHlWDtCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to convert some column as index\n",
        "\n",
        "df = df.read_csv(\"data.csv\", index_col = 'enrollment')"
      ],
      "metadata": {
        "id": "zgcPEXOkDrC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Header Parameter"
      ],
      "metadata": {
        "id": "K93JnKG5D-gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IF we have to assign first row or any row of dataset as header names then do \n",
        "\n",
        "df = df.read_csv(\"data.csv\", header=1) # 1 --> first row of dataset"
      ],
      "metadata": {
        "id": "WyDC7lU0D9Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. use_col"
      ],
      "metadata": {
        "id": "qeLy_OQZEVH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use only some of the columns of the dataset\n",
        "\n",
        "pd.read_csv('data.csv', usecols=['enroll','name']) # and it drops rest of the columns of the dataset"
      ],
      "metadata": {
        "id": "zKi5fJpZEXZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Sequeeze "
      ],
      "metadata": {
        "id": "YhPsI34_ExrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use one col and sequeze it into series\n",
        "\n",
        "df = df.read_csv(\"data.csv\", usecols=['enroll'], squeeze = True)"
      ],
      "metadata": {
        "id": "VDQNPRtMExU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Skiprows/nrows"
      ],
      "metadata": {
        "id": "zEybY0tUFE8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.read_csv(\"data.csv\", skiprows =[0,5])\n",
        "\n",
        "df = df.read_csv(\"data.csv\", nrows=100)"
      ],
      "metadata": {
        "id": "Zwi9yGvCFJtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Encoding \n"
      ],
      "metadata": {
        "id": "de_mOpOsFRNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#by default encoding is utf8 but we can have different encoding, to read them use\n",
        "\n",
        "df = df.read_csv(\"data.csv\", encoding ='latin-1')\n",
        "\n",
        "\n",
        "# the error it will be throwing is * UnicodeDecodeError *   ----> means its not able to read this encode of data if encoding is default"
      ],
      "metadata": {
        "id": "T0ZgDW-IFVIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Skip bad lines"
      ],
      "metadata": {
        "id": "5sqce-xaF6Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose if we have some rows having extra number of columns then other rows \n",
        "\n",
        "df = df.read_csv(\"data.csv\", error_bad_lines= False)"
      ],
      "metadata": {
        "id": "sgor5Hu9F0XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. dtype "
      ],
      "metadata": {
        "id": "PMb_RL2ZGOxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose if one row while reading the data is detected as float data type but u want it to be int type then do\n",
        "\n",
        "df = df.read_csv(\"data.csv\", dtype={'col_name', int}"
      ],
      "metadata": {
        "id": "H-ItEJTNGRVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Handling Dates"
      ],
      "metadata": {
        "id": "woi2RY4jGlxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# want to read date column as date \n",
        "\n",
        "pd.read_csv('data.csv', Parse_dates = [column_name])"
      ],
      "metadata": {
        "id": "Wb20jMKMGvdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Converters"
      ],
      "metadata": {
        "id": "_MWwME1pHApj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# want to convert some name to alias\n",
        "\n",
        "def rename(name):\n",
        "  if name == \"Jammu and Kashmir\":\n",
        "    return \"J&K\"\n",
        "  else:\n",
        "    return Name\n",
        "\n",
        "df = df.read_csv(\"data.csv\", converters = {\"Col_Name\":rename})"
      ],
      "metadata": {
        "id": "4fJUjvfWHFe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. na_values"
      ],
      "metadata": {
        "id": "NnMD2o_3HiWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if u want to consider some notation to be read as NAN value \n",
        "\n",
        "df = df.read_csv(\"data.csv\", na_values=['-','/','\\','NAN']) # is the list of values to be considered as NAN"
      ],
      "metadata": {
        "id": "zBG8Axq6HlTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Loading a huge dataset in chunks"
      ],
      "metadata": {
        "id": "SxUxMP5xH66K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.read_csv(\"data.csv\", chunks = 5000)\n",
        "\n",
        "for chunks in df:\n",
        "  # perform any operation\n",
        "  "
      ],
      "metadata": {
        "id": "KGSBXRUjH_ss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}